{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9c78d5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "259477d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import IterableDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee3162",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "093c9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/mystic/Programming/mystic-bot/notebooks\"\n",
    "pgn_file = f\"{base_dir}/data/lichess_db_standard_rated_2014-07.pgn\"\n",
    "pt_file = f\"{base_dir}/data/lichess_2014_07.pt\"\n",
    "model_dir = f\"{base_dir}/models\"\n",
    "plot_dir = f\"{base_dir}/plots\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3638c00",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "afd02f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1 CUDA device(s) available:\n",
      "  ‚îî‚îÄ [0] NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"‚úÖ {device_count} CUDA device(s) available:\")\n",
    "    for i in range(device_count):\n",
    "        print(f\"  ‚îî‚îÄ [{i}] {torch.cuda.get_device_name(i)}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CUDA not available, using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d0fae",
   "metadata": {},
   "source": [
    "# Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ae9204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cdc62764b94c72a1ba8ab6729d4689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing PGN:   0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 71\u001b[0m\n\u001b[1;32m     67\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(output_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboards\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(boards),\n\u001b[1;32m     69\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevals\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(evals)}, output_path)\n\u001b[0;32m---> 71\u001b[0m \u001b[43mpreprocess_pgn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpgn_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpt_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_games\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[101], line 28\u001b[0m, in \u001b[0;36mpreprocess_pgn\u001b[0;34m(pgn_path, output_path, max_games)\u001b[0m\n\u001b[1;32m     25\u001b[0m games_processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m games_processed \u001b[38;5;241m<\u001b[39m max_games:\n\u001b[0;32m---> 28\u001b[0m     game \u001b[38;5;241m=\u001b[39m \u001b[43mchess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpgn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m game \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Programming/mystic-bot/.env/lib/python3.12/site-packages/chess/pgn.py:1608\u001b[0m, in \u001b[0;36mread_game\u001b[0;34m(handle, Visitor)\u001b[0m\n\u001b[1;32m   1605\u001b[0m             line \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m   1606\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1608\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found_game:\n\u001b[1;32m   1611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EVAL_REGEX = re.compile(r\"\\[%eval (-?\\d+(\\.\\d+)?)\\]\")\n",
    "ENCODE_PIECES = {\n",
    "    'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "    'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "}\n",
    "\n",
    "\n",
    "def encode_board(fen):\n",
    "    board_tensor = np.zeros((12, 8, 8), dtype=np.float32)\n",
    "    board = chess.Board(fen)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            idx = ENCODE_PIECES[piece.symbol()]\n",
    "            row, col = divmod(square, 8)\n",
    "            board_tensor[idx, 7 - row, col] = 1\n",
    "    return board_tensor\n",
    "\n",
    "\n",
    "def preprocess_pgn(pgn_path, output_path, max_games=1_000_000):\n",
    "    if os.path.exists(pt_file):\n",
    "        print(f\"\\n‚úÖ PT file already exists!\")\n",
    "    boards, evals = [], []\n",
    "    with open(pgn_path, encoding=\"utf-8\") as f:\n",
    "        pbar = tqdm(total=max_games, desc=\"Preprocessing PGN\")\n",
    "        games_processed = 0\n",
    "\n",
    "        while games_processed < max_games:\n",
    "            game = chess.pgn.read_game(f)\n",
    "            pbar.update(1)\n",
    "            if game is None:\n",
    "                break\n",
    "\n",
    "            board = game.board()\n",
    "            added_this_game = 0\n",
    "\n",
    "            for node in game.mainline():\n",
    "                if \"eval\" in node.comment:\n",
    "                    match = EVAL_REGEX.search(node.comment)\n",
    "                    if match:\n",
    "                        try:\n",
    "                            score = float(match.group(1))\n",
    "                            score = max(min(score, 10), -10)\n",
    "                            if board.turn == chess.BLACK:\n",
    "                                score = -score\n",
    "\n",
    "                            board_tensor = encode_board(board.fen())\n",
    "                            boards.append(board_tensor)\n",
    "                            evals.append(score)\n",
    "                            added_this_game += 1\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "                if node.move:\n",
    "                    board.push(node.move)\n",
    "\n",
    "            if added_this_game > 0:\n",
    "                games_processed += 1\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "    boards = np.stack(boards)\n",
    "    evals = np.array(evals, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved {len(boards)} positions from {games_processed} games.\")\n",
    "\n",
    "    # Save to disk\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    torch.save({\"boards\": torch.tensor(boards),\n",
    "               \"evals\": torch.tensor(evals)}, output_path)\n",
    "\n",
    "preprocess_pgn(pgn_file, pt_file, max_games=1_048_440)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9fced",
   "metadata": {},
   "source": [
    "# Dataset Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f995653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tensor_file, split=\"train\"):\n",
    "        data = torch.load(tensor_file)\n",
    "        boards = data[\"boards\"]\n",
    "        evals = data[\"evals\"]\n",
    "\n",
    "        # Split logic: 70/10/20\n",
    "        total = len(boards)\n",
    "        if split == \"train\":\n",
    "            self.boards = boards[:int(0.7 * total)]\n",
    "            self.evals = evals[:int(0.7 * total)]\n",
    "        elif split == \"val\":\n",
    "            self.boards = boards[int(0.7 * total):int(0.8 * total)]\n",
    "            self.evals = evals[int(0.7 * total):int(0.8 * total)]\n",
    "        elif split == \"test\":\n",
    "            self.boards = boards[int(0.8 * total):]\n",
    "            self.evals = evals[int(0.8 * total):]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split: {split}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.boards)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.boards[idx], self.evals[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f0916",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3a38a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 64, 8, 8]          10,432\n",
      "              ReLU-2             [-1, 64, 8, 8]               0\n",
      "            Conv2d-3            [-1, 128, 8, 8]          73,856\n",
      "              ReLU-4            [-1, 128, 8, 8]               0\n",
      "           Flatten-5                 [-1, 8192]               0\n",
      "            Linear-6                  [-1, 512]       4,194,816\n",
      "              ReLU-7                  [-1, 512]               0\n",
      "            Linear-8                    [-1, 1]             513\n",
      "================================================================\n",
      "Total params: 4,279,617\n",
      "Trainable params: 4,279,617\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.26\n",
      "Params size (MB): 16.33\n",
      "Estimated Total Size (MB): 16.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class EvalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(18, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "model = EvalNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "summary(model, input_size=(18, 8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882a03c",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2e10751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2870, 410, 820)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "valid_games = 0.41\n",
    "\n",
    "train_loader = DataLoader(PGNEvalDataset(pt_file, split=\"train\"), batch_size=batch_size)\n",
    "val_loader = DataLoader(PGNEvalDataset(pt_file, split=\"val\"), batch_size=batch_size)\n",
    "test_loader = DataLoader(PGNEvalDataset(pt_file, split=\"test\"), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811960ed",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0735326b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3688eeb11ae41d49dceaeb37308f363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 1] Training:   0%|          | 0/2870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c496df4473e049108eb04fdb6018795e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 1] Validation:   0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] ‚úÖ Train Loss: 16.4871 | Val Loss: 18.3479\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c521cef0add49c2b63473f4c6b586ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 2] Training:   0%|          | 0/2870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f553b9f9442d4ca9a46dc89de98eafc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 2] Validation:   0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] ‚úÖ Train Loss: 16.0373 | Val Loss: 17.1922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfa84172ee14248bf8a324f1d78ef5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 3] Training:   0%|          | 0/2870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1ec504abd84290a06a3be4139031f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Epoch 3] Validation:   0%|          | 0/410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     35\u001b[0m     num_val_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_pbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programming/mystic-bot/.env/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/mystic-bot/.env/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Programming/mystic-bot/.env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/Programming/mystic-bot/.env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Programming/mystic-bot/.env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:33\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[92], line 41\u001b[0m, in \u001b[0;36mPGNEvalDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m game_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     game \u001b[38;5;241m=\u001b[39m \u001b[43mchess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpgn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m game \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_games \u001b[38;5;129;01mand\u001b[39;00m game_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_games):\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/mystic-bot/.env/lib/python3.12/site-packages/chess/pgn.py:1680\u001b[0m, in \u001b[0;36mread_game\u001b[0;34m(handle, Visitor)\u001b[0m\n\u001b[1;32m   1677\u001b[0m fresh_line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m MOVETEXT_REGEX\u001b[38;5;241m.\u001b[39mfinditer(line):\n\u001b[0;32m-> 1680\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[43mmatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1683\u001b[0m         \u001b[38;5;66;03m# Consume until the end of the comment.\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m         start_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float(\"inf\")\n",
    "plt.ion()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_train = 0.0\n",
    "    pbar = tqdm(\n",
    "        train_loader, desc=f\"[Epoch {epoch+1}] Training\", total=len(train_loader), leave=False)\n",
    "\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).squeeze()\n",
    "        loss = loss_fn(pred, y.squeeze())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train += loss.item()\n",
    "\n",
    "        pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_train = running_train / len(train_loader)\n",
    "    train_losses.append(avg_train)\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    running_val = 0.0\n",
    "    val_pbar = tqdm(\n",
    "        val_loader, desc=f\"[Epoch {epoch+1}] Validation\", total=len(val_loader), leave=False)\n",
    "    with torch.no_grad():\n",
    "        num_val_batches = 0\n",
    "        for x, y in val_pbar:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).squeeze()\n",
    "            loss = loss_fn(pred, y.squeeze())\n",
    "            running_val += loss.item()\n",
    "            num_val_batches += 1\n",
    "\n",
    "            val_pbar.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    avg_val = running_val / len(val_loader)\n",
    "    val_losses.append(avg_val)\n",
    "\n",
    "    # --- Logging ---\n",
    "    print(\n",
    "        f\"[Epoch {epoch+1}] ‚úÖ Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f}\")\n",
    "\n",
    "    # --- Checkpointing ---\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, f\"{timestamp}.pt\"))\n",
    "    if avg_val < best_val_loss:\n",
    "        best_val_loss = avg_val\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, \"best.pt\"))\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10, 6), dpi=150)\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(plot_dir, \"loss_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c1ce1",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir, \"best.pt\")))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "print(\"\\nüîç Evaluating on test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\", total=len(test_loader), leave=False)\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).squeeze()\n",
    "        loss = loss_fn(pred, y.squeeze())\n",
    "        test_loss += loss.item()\n",
    "        pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"\\nüß™ Test Loss: {avg_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
